{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5123\n",
      "   permno    date  Opndt  Mopnprc  Mclsprc  Mnshrtrd  Mnvaltrd  Msmvosd  \\\n",
      "0       2  199101    1.0     -1.0     -1.0       0.6      -1.0      1.0   \n",
      "1       2  199102   -0.2     -1.0     -1.0       1.0       0.6      1.0   \n",
      "2       2  199103   -1.0     -1.0     -1.0       1.0       0.2      1.0   \n",
      "3       2  199104    1.0     -1.0     -1.0       0.2      -0.2      1.0   \n",
      "4       2  199105   -1.0     -1.0     -1.0       1.0       0.6      1.0   \n",
      "\n",
      "     ret-rf  ret-rf-new  \n",
      "0  0.036103    0.039972  \n",
      "1  0.039972   -0.126574  \n",
      "2 -0.126574   -0.116085  \n",
      "3 -0.116085   -0.030901  \n",
      "4 -0.030901   -0.303809  \n",
      "        permno    date  Opndt   Mopnprc   Mclsprc  Mnshrtrd  Mnvaltrd  \\\n",
      "667375  900957  202212   -1.0 -0.990130 -0.990541 -0.950236 -0.994242   \n",
      "667376  900957  202301   -1.0 -0.990558 -0.990148 -0.933498 -0.990558   \n",
      "667377  900957  202302   -1.0 -0.990398 -0.991011 -0.968539 -0.996731   \n",
      "667378  900957  202303   -1.0 -0.991071 -0.991071 -0.954951 -0.995942   \n",
      "667379  900957  202304   -1.0 -0.991136 -0.990733 -0.956487 -0.997180   \n",
      "\n",
      "         Msmvosd    ret-rf  ret-rf-new  \n",
      "667375 -0.990130 -0.078434    0.037231  \n",
      "667376 -0.992200  0.037231   -0.020520  \n",
      "667377 -0.991420 -0.020520   -0.080282  \n",
      "667378 -0.991883 -0.080282   -0.003795  \n",
      "667379 -0.990733 -0.003795   -0.030478  \n"
     ]
    }
   ],
   "source": [
    "df_final=pd.read_feather('./China.feather')\n",
    "characteristics = df_final.columns.to_list()\n",
    "characteristics.remove(\"ret-rf\")\n",
    "characteristics.remove(\"ret-rf-new\")\n",
    "characteristics.remove(\"permno\")\n",
    "characteristics.remove(\"date\")\n",
    "print(len(characteristics))\n",
    "df_final[characteristics+['ret-rf']] = df_final[characteristics+['ret-rf']] .fillna(0) # 参考machine-learning-for-trading/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb中的方式\n",
    "firm_all=df_final['permno'].unique()\n",
    "print(len(firm_all))\n",
    "n_characteristics=len(characteristics)\n",
    "print(df_final.head())\n",
    "print(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_train = 199101\n",
    "end_date_train = 202101\n",
    "start_date_val = 202101\n",
    "end_date_val = 202312\n",
    "df_train = df_final[(df_final['date'] >= start_date_train) & (df_final['date'] < end_date_train)]\n",
    "df_val = df_final[(df_final['date'] >= start_date_val) & (df_final['date'] < end_date_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222711774415895\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca.fit(df_train[characteristics])\n",
    "reg = LinearRegression()\n",
    "reg.fit(pca.transform(df_train[characteristics]), df_train['ret-rf'])\n",
    "output = reg.predict(pca.transform(df_val[characteristics]))\n",
    "r2 = 1 - ((df_val['ret-rf'].to_numpy() - output) ** 2).sum() / (df_val['ret-rf'].to_numpy() ** 2).sum()\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767\n",
      "0.0287411153942282\n",
      "-0.03863195120862436\n",
      "2767\n",
      "0.04940180731174667\n",
      "-0.05827311754690058\n",
      "2767\n",
      "0.06662117454083473\n",
      "-0.10598970143104862\n",
      "2767\n",
      "0.08807170420306633\n",
      "-0.26109315110504683\n",
      "2767\n",
      "0.2656744431986707\n",
      "-0.05762797608742177\n",
      "2767\n",
      "0.37645673502075117\n",
      "0.18452272589328272\n"
     ]
    }
   ],
   "source": [
    "start_date_train = 199101\n",
    "end_date_train = 202101\n",
    "start_date_val = 202101\n",
    "end_date_val = 202312\n",
    "for n_components in range(1, 7):\n",
    "    r2s_train = []\n",
    "    r2s_val = []\n",
    "    lengths = []\n",
    "    for _, each_df in df_final.groupby(by='permno'):\n",
    "        each_df_train = each_df[(each_df['date'] >= start_date_train) & (each_df['date'] < end_date_train)]\n",
    "        each_df_val = each_df[(each_df['date'] >= start_date_val) & (each_df['date'] < end_date_val)]\n",
    "        if (len(each_df_train) >= 50 and len(each_df_val) >= 10):\n",
    "            lengths.append(len(each_df))\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(each_df_train[characteristics])\n",
    "            reg = LinearRegression()\n",
    "            reg.fit(pca.transform(each_df_train[characteristics]), each_df_train['ret-rf'])\n",
    "            output = reg.predict(pca.transform(each_df_train[characteristics]))\n",
    "            r2 = 1 - ((each_df_train['ret-rf'].to_numpy() - output) ** 2).sum() / (each_df_train['ret-rf'].to_numpy() ** 2).sum()\n",
    "            r2s_train.append(r2)\n",
    "            output = reg.predict(pca.transform(each_df_val[characteristics]))\n",
    "            r2 = 1 - ((each_df_val['ret-rf'].to_numpy() - output) ** 2).sum() / (each_df_val['ret-rf'].to_numpy() ** 2).sum()\n",
    "            r2s_val.append(r2)\n",
    "    print(len(lengths))\n",
    "    # print(sum(1 for i in lengths if i >= 200))\n",
    "    print(sum(r2s_train) / len(r2s_train))\n",
    "    print(sum(r2s_val) / len(r2s_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n",
      "0.04532934649651339\n",
      "0.006718646969672622\n",
      "736\n",
      "0.07196348773769772\n",
      "0.09164112357010472\n",
      "736\n",
      "0.10761750536975892\n",
      "0.1791660535084386\n",
      "736\n",
      "0.20097681107087378\n",
      "0.39759548214345175\n",
      "736\n",
      "0.35578221142270255\n",
      "0.266091086804168\n",
      "736\n",
      "0.42165592879886127\n",
      "0.6561138886438577\n"
     ]
    }
   ],
   "source": [
    "start_date_trains = [199101, 200101, 201101]\n",
    "end_date_trains = [200001, 201001, 202201]\n",
    "start_date_vals = [200001, 201001, 202201]\n",
    "end_date_vals = [200101, 201101, 202312]\n",
    "for n_components in range(1, 7):\n",
    "    r2s_train = []\n",
    "    r2s_val = []\n",
    "    lengths = []\n",
    "    for _, each_df in df_final.groupby(by='permno'):\n",
    "        each_df_trains = []\n",
    "        each_df_vals = []\n",
    "        for i in range(len(start_date_trains)):\n",
    "            each_df_trains.append(each_df[(each_df['date'] >= start_date_trains[i]) & (each_df['date'] < end_date_trains[i])])\n",
    "            each_df_vals.append(each_df[(each_df['date'] >= start_date_vals[i]) & (each_df['date'] < end_date_vals[i])])\n",
    "        # print(len(each_df_trains))\n",
    "        # print(len(each_df_vals))\n",
    "        each_df_train = pd.concat(each_df_trains)\n",
    "        each_df_val = pd.concat(each_df_vals)\n",
    "        if (all(len(each_df_train_decade) >= 10 for each_df_train_decade in each_df_trains) and \n",
    "            all(len(each_df_val_decade) >= 2 for each_df_val_decade in each_df_vals)):\n",
    "            # print([len(each_df_train_decade) for each_df_train_decade in each_df_trains])\n",
    "            # print([len(each_df_val_decade) for each_df_val_decade in each_df_vals])\n",
    "            lengths.append(len(each_df))\n",
    "            pca_first_step = PCA(n_components=6)\n",
    "            pca_first_step.fit(each_df_train[characteristics])\n",
    "            pcas_second_step = []\n",
    "            regs = []\n",
    "            r2_numerator_train = 0; r2_denominator_train = 0; r2_numerator_val = 0; r2_denominator_val = 0\n",
    "            for each_df_train_decade, each_df_val_decade in zip(each_df_trains, each_df_vals):\n",
    "                pca_second_step = PCA(n_components=n_components)\n",
    "                pcas_second_step.append(pca_second_step)\n",
    "                pca_second_step.fit(pca_first_step.transform(each_df_train_decade[characteristics]))\n",
    "                reg = LinearRegression()\n",
    "                regs.append(reg)\n",
    "                reg.fit(pca_second_step.transform(pca_first_step.transform(each_df_train_decade[characteristics])), each_df_train_decade['ret-rf'])\n",
    "                output = reg.predict(pca_second_step.transform(pca_first_step.transform(each_df_train_decade[characteristics])))\n",
    "                r2_numerator_train += ((each_df_train_decade['ret-rf'].to_numpy() - output) ** 2).sum()\n",
    "                r2_denominator_train += (each_df_train_decade['ret-rf'].to_numpy() ** 2).sum()\n",
    "                output = reg.predict(pca_second_step.transform(pca_first_step.transform(each_df_val_decade[characteristics])))\n",
    "                r2_numerator_val += ((each_df_val_decade['ret-rf'].to_numpy() - output) ** 2).sum()\n",
    "                r2_denominator_val += (each_df_val_decade['ret-rf'].to_numpy() ** 2).sum()\n",
    "            r2 = 1 - r2_numerator_train / r2_denominator_train\n",
    "            r2s_train.append(r2)\n",
    "            r2 = 1 - r2_numerator_val / r2_denominator_val\n",
    "            r2s_val.append(r2)\n",
    "    print(len(lengths))\n",
    "    # print(sum(1 for i in lengths if i >= 200))\n",
    "    print(sum(r2s_train) / len(r2s_train))\n",
    "    print(abs(sum(r2s_val) / len(r2s_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_trains = [199101, 200101, 201101]\n",
    "end_date_trains = [200001, 201001, 202201]\n",
    "start_date_vals = [200001, 201001, 202201]\n",
    "end_date_vals = [200101, 201101, 202312]\n",
    "df_alternate = df_final[(df_final['date'] >= start_date_trains[0]) & (df_final['date'] < end_date_vals[-1])]\\\n",
    "    .set_index(['permno', 'date'])[characteristics].stack().unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alternate['X_factor'] = 0\n",
    "X_factors = []\n",
    "df_final.fillna(0)\n",
    "for date, each_df in df_final[(df_final['date'] >= start_date_trains[0]) & (df_final['date'] < end_date_vals[-1])].groupby(by='date'):\n",
    "    try:\n",
    "        # X_factor = np.linalg.solve(each_df[characteristics].values.T @ each_df[characteristics].values, each_df[characteristics].values.T @ each_df['ret-rf'].values)\n",
    "        X_factor = np.linalg.pinv(each_df[characteristics].values.T @ each_df[characteristics].values) @ each_df[characteristics].values.T @ each_df['ret-rf'].values\n",
    "        # print(X_factor)\n",
    "    except np.linalg.LinAlgError:\n",
    "        continue\n",
    "    s = pd.Series(characteristics, X_factor)\n",
    "    s['date'] = date\n",
    "    df_alternate.loc[:, 'X_factor'] = pd.Series(X_factor, pd.MultiIndex.from_tuples([(date, a) for a in characteristics]))\n",
    "    X_factors.append(pd.Series(X_factor, pd.MultiIndex.from_tuples([(date, a) for a in characteristics])))\n",
    "    # print(X_factors[-1])\n",
    "df_alternate['X_factor'] = pd.concat(X_factors)\n",
    "df_alternate = df_alternate.reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.26703909670648346\n",
      "0.3104276382975009\n",
      "6\n",
      "0.2701638374166199\n",
      "0.2836415798675022\n",
      "6\n",
      "0.27930174104161326\n",
      "0.3285581846111965\n",
      "6\n",
      "0.2814585267279462\n",
      "0.308554133443639\n",
      "6\n",
      "0.28182611092055504\n",
      "0.34259166870880686\n",
      "6\n",
      "0.28415591658476563\n",
      "0.3854151738098688\n"
     ]
    }
   ],
   "source": [
    "permnos = df_alternate.columns.to_list()\n",
    "permnos.remove('X_factor')\n",
    "permnos.remove('date')\n",
    "permnos.remove('level_1')\n",
    "for n_components in range(1, 7):\n",
    "    r2s_train = []\n",
    "    r2s_val = []\n",
    "    lengths = []\n",
    "    for _, each_df in df_alternate.groupby(by='level_1'):\n",
    "        each_df_trains = []\n",
    "        each_df_vals = []\n",
    "        for i in range(len(start_date_trains)):\n",
    "            each_df_trains.append(each_df[(each_df['date'] >= start_date_trains[i]) & (each_df['date'] < end_date_trains[i])])\n",
    "            each_df_vals.append(each_df[(each_df['date'] >= start_date_vals[i]) & (each_df['date'] < end_date_vals[i])])\n",
    "        # print(len(each_df_trains))\n",
    "        # print(len(each_df_vals))\n",
    "        # print(each_df_trains[0])\n",
    "        each_df_train = pd.concat(each_df_trains)\n",
    "        each_df_val = pd.concat(each_df_vals)\n",
    "        # if (all(each_df_train_decade.shape[0] * each_df_train_decade.shape[1] >= 2 * (each_df_train_decade == 0).to_numpy().sum() for each_df_train_decade in each_df_trains) and \n",
    "        #     all(each_df_val_decade.shape[0] * each_df_val_decade.shape[1] >= 2 * (each_df_val_decade == 0).to_numpy().sum() for each_df_val_decade in each_df_vals)):\n",
    "        if (all(len(each_df_train_decade) >= 10 for each_df_train_decade in each_df_trains) and \n",
    "            all(len(each_df_val_decade) >= 2 for each_df_val_decade in each_df_vals)):\n",
    "            # print([len(each_df_train_decade) for each_df_train_decade in each_df_trains])\n",
    "            # print([len(each_df_val_decade) for each_df_val_decade in each_df_vals])\n",
    "            lengths.append(len(each_df))\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(each_df_train[permnos])\n",
    "            reg = LinearRegression()\n",
    "            reg.fit(pca.transform(each_df_train[permnos]), each_df_train['X_factor'])\n",
    "            output = reg.predict(pca.transform(each_df_train[permnos]))\n",
    "            r2 = 1 - ((each_df_train['X_factor'] - output) ** 2).sum() / (each_df_train['X_factor'] ** 2).sum()\n",
    "            r2s_train.append(r2)\n",
    "            output = reg.predict(pca.transform(each_df_val[permnos]))\n",
    "            r2 = 1 - ((each_df_val['X_factor'] - output) ** 2).sum() / (each_df_val['X_factor'] ** 2).sum()\n",
    "            r2s_val.append(r2)\n",
    "    print(len(lengths))\n",
    "    # print(sum(1 for i in lengths if i >= 200))\n",
    "    print(sum(r2s_train) / len(r2s_train))\n",
    "    print(abs(sum(r2s_val) / len(r2s_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.28311549915060463\n",
      "0.34899589505949025\n",
      "6\n",
      "0.29352450364368327\n",
      "0.2790693238983149\n",
      "6\n",
      "0.3017164721836972\n",
      "0.2435292403013154\n",
      "6\n",
      "0.30568851220295423\n",
      "0.22939874288338222\n",
      "6\n",
      "0.3089384620684558\n",
      "0.34331253822803937\n",
      "6\n",
      "0.31066167349859547\n",
      "0.20090801718779602\n"
     ]
    }
   ],
   "source": [
    "permnos = df_alternate.columns.to_list()\n",
    "permnos.remove('X_factor')\n",
    "permnos.remove('date')\n",
    "permnos.remove('level_1')\n",
    "for n_components in range(1, 7):\n",
    "    r2s_train = []\n",
    "    r2s_val = []\n",
    "    lengths = []\n",
    "    for _, each_df in df_alternate.groupby(by='level_1'):\n",
    "        each_df_trains = []\n",
    "        each_df_vals = []\n",
    "        for i in range(len(start_date_trains)):\n",
    "            each_df_trains.append(each_df[(each_df['date'] >= start_date_trains[i]) & (each_df['date'] < end_date_trains[i])])\n",
    "            each_df_vals.append(each_df[(each_df['date'] >= start_date_vals[i]) & (each_df['date'] < end_date_vals[i])])\n",
    "        # print(len(each_df_trains))\n",
    "        # print(len(each_df_vals))\n",
    "        # print(each_df_trains[0])\n",
    "        each_df_train = pd.concat(each_df_trains)\n",
    "        each_df_val = pd.concat(each_df_vals)\n",
    "        # if (all(each_df_train_decade.shape[0] * each_df_train_decade.shape[1] >= 2 * (each_df_train_decade == 0).to_numpy().sum() for each_df_train_decade in each_df_trains) and \n",
    "        #     all(each_df_val_decade.shape[0] * each_df_val_decade.shape[1] >= 2 * (each_df_val_decade == 0).to_numpy().sum() for each_df_val_decade in each_df_vals)):\n",
    "        if (all(len(each_df_train_decade) >= 10 for each_df_train_decade in each_df_trains) and \n",
    "            all(len(each_df_val_decade) >= 2 for each_df_val_decade in each_df_vals)):\n",
    "            # print([len(each_df_train_decade) for each_df_train_decade in each_df_trains])\n",
    "            # print([len(each_df_val_decade) for each_df_val_decade in each_df_vals])\n",
    "            lengths.append(len(each_df))\n",
    "            pca_first_step = PCA(n_components=60)\n",
    "            pca_first_step.fit(each_df_train[permnos])\n",
    "            pcas_second_step = []\n",
    "            regs = []\n",
    "            r2_numerator_train = 0; r2_denominator_train = 0; r2_numerator_val = 0; r2_denominator_val = 0\n",
    "            for each_df_train_decade, each_df_val_decade in zip(each_df_trains, each_df_vals):\n",
    "                pca_second_step = PCA(n_components=n_components)\n",
    "                pcas_second_step.append(pca_second_step)\n",
    "                pca_second_step.fit(pca_first_step.transform(each_df_train_decade[permnos]))\n",
    "                reg = LinearRegression()\n",
    "                regs.append(reg)\n",
    "                reg.fit(pca_second_step.transform(pca_first_step.transform(each_df_train_decade[permnos])), each_df_train_decade['X_factor'])\n",
    "                output = reg.predict(pca_second_step.transform(pca_first_step.transform(each_df_train_decade[permnos])))\n",
    "                # print(output)\n",
    "                r2_numerator_train += ((each_df_train_decade['X_factor'].to_numpy() - output) ** 2).sum()\n",
    "                r2_denominator_train += (each_df_train_decade['X_factor'].to_numpy() ** 2).sum()\n",
    "                output = reg.predict(pca_second_step.transform(pca_first_step.transform(each_df_val_decade[permnos])))\n",
    "                r2_numerator_val += ((each_df_val_decade['X_factor'].to_numpy() - output) ** 2).sum()\n",
    "                r2_denominator_val += (each_df_val_decade['X_factor'].to_numpy() ** 2).sum()\n",
    "            r2 = 1 - r2_numerator_train / r2_denominator_train\n",
    "            r2s_train.append(r2)\n",
    "            r2 = 1 - r2_numerator_val / r2_denominator_val\n",
    "            r2s_val.append(r2)\n",
    "    print(len(lengths))\n",
    "    # print(sum(1 for i in lengths if i >= 200))\n",
    "    print(sum(r2s_train) / len(r2s_train))\n",
    "    print(abs(sum(r2s_val) / len(r2s_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
